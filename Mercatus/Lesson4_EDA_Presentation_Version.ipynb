{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LunchAndLearnLesson4_MissingCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serenamm/Speaking/blob/master/Mercatus/Lesson4_EDA_Presentation_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Lb6iSzAHDe5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The data science work flow:\n",
        "\n",
        "1. Load it\n",
        "2. Take a peek at it \n",
        "3. Clean it\n",
        "4. Explore it: Make plots and observations.\n",
        "5. Make comments in-line for readability purposes.\n",
        "6. Build a model! \n",
        "\n",
        "I've done everything except points 2 and 4 for you all. We'll go through the first 5, but will come up with our observations all together. Point 6 will be left for the next lesson."
      ]
    },
    {
      "metadata": {
        "id": "ceLvHdt1SgLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# So... what are the tools we'll be using?\n",
        "\n",
        "1. ***Google Colaboratory:***\n",
        "Google \"Colab\" is a service that provides free cloud-based Jupyter Notebooks that give you free GPU to work on. It's awesome.\n",
        "\n",
        "2. ***Jupyter Notebook:*** Jupyter is like a scientific notebook for coding, where you can mix cells of code with cells of output (containing figures and results) in one notebook. Think of chemistry and physics experiements in school, where you would write the details of your experiments with the results all in one notebook. That's what Jupyter allows you to do, except for data and code.\n",
        "\n",
        "3. ***Pandas:***\n",
        "Pandas is a Python library for data manipulation and analysis. Pandas and data science go hand in hand.\n",
        "\n",
        "4. ***DataFrames:***\n",
        "Not necessarily a tool in their own right, but it's the most useful object in the Pandas library, and again, shows up all over the place in data science. Formally, it's a 2-dimensional labeled data structure with columns of potentially different types. Informally, it's like a SQL table. Or Excel table. It's just a table.\n",
        "\n",
        "5. ***NumPy:***\n",
        "Numpy is a Python library for array and matrix manipulation, along with mathematical functions for these arrays and matrices. Again, it's very fundamental in data science work.\n",
        "\n",
        "6. ***Matplotlib:***\n",
        "Matplotlib is the most popular plotting library for Python, and it's supposed to be an extension of NumPy. \n",
        "\n",
        "7. ***Seaborn:***\n",
        "Seaborn is another plotting library that's actually an API on top of Matplitlib. It's more user friendly than Matplotlib, and makes nicer charts. Many people prefer it (myself included).\n",
        "\n",
        "8. ***Scikit-learn:***\n",
        "Scikit-learn, aka sklearn, or simly scikit, is a machine learning library for Python. It's usually the first library that everyone learns when starting out with machine learning.\n",
        "\n",
        "9. ***StatsModels:***\n",
        "Statsmodels is a package that allows you to do statistics in Python. It's more heavily focussed on the statistics rather than machine learning side of things. Think of it as a more mathematically rigorous package, as compared to scikit-learn. \n",
        "\n",
        "10. ***LIME:***\n",
        "The LIME package (Local Interpretable Model-Agnostic Explanations) gives a local (i.e. single classification) explanation of feature importance. Similar to how what is important to one person's identity may be irrelevant to someone else's, a feature may be more important to the classification of one shopper, while for another shopper, it's a different feature that is the most important. LIME helps us look at feature importance on a case by case basis."
      ]
    },
    {
      "metadata": {
        "id": "Rqb8jFZxh0lC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# And what data will we be using?\n",
        "\n",
        "We'll be using a subset of Instacart's 3 millions orders dataset, with shoppers labelled as pet owners (\"pet=1\") and non-pet owners (\"pet=0\"). So the data has been worked with a bit. Here's a link to the Medium article where Instacart introduces the dataset: https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2 .\n",
        "\n",
        "# And what will we be doing with it?\n",
        "\n",
        "When you build out a data science project, it's important to have a goal. Your goal can be open ended like:\n",
        "\n",
        "\"Let's explore the data and see if there's anything interesting in it.\"\n",
        "\n",
        "Or, it can be fairly closed, like:\n",
        "\n",
        "\"I want to model the relationship between peanut butter consumption and marriage rate.\" (The example here is made up and the idea is borrowed from this site, check it out for some funny \"spurious\" correlations! http://www.tylervigen.com/spurious-correlations ).\n",
        "\n",
        "If you find something interesting in the data that you didn't expect, that could be of real business value, so you likely will want to create a model to capture the phenonema. Or, if you find information in your data to back up a previous hypothesis, you again will likely want to create a model. Making a model isn't always the end goal of data exploration, but in the data scientist's workflow, it often is. (A data analyst on the other hand, may dive deeper into picking out business insights from data, rather than focussing on modelling)\n",
        "\n",
        "In our two sessions, our goal will be to create a model to predict if someone is a pet owner or not, based on their shopping purchases, *excluding products from the pet department*."
      ]
    },
    {
      "metadata": {
        "id": "OSrKRykan1WD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's code! \n",
        "\n",
        "# First, read in the data\n",
        "\n",
        "Note that you have to reload data each time you open the file\n",
        "This takes a while- about 15 mins for a file of 114 mb.\n",
        "The file we use is .../Lunch&Learn/LL4/instacart_data.csv\n"
      ]
    },
    {
      "metadata": {
        "id": "REm0iuonn5In",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxowXqzCufrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# This is the way you read csv files into Colab,\n",
        "# usually you can do pd.read_csv(file_name)\n",
        "df = pd.read_csv(io.StringIO(uploaded['instacart_data.csv'].decode('utf-8')))\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mh6wRPzxbzt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's get rid of that unnamed column\n",
        "cols = [\"user_id\",\"product_id\", \"reordered\", \"product_name\", \n",
        "        \"aisle_id\", \"department_id\", \"order_dow\",\n",
        "        \"order_hour_of_day\", \"pet\", \"department\"]\n",
        "df = df[cols]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMxuu_RCx1oW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's start by cleaning our data"
      ]
    },
    {
      "metadata": {
        "id": "Mmbs6CEvx5MZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "\n",
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ChFzD7IcjFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Insert summary here."
      ]
    },
    {
      "metadata": {
        "id": "jQAViWSPyakH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Size of data\n",
        "\n",
        "# Insert code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctDkL2KVcqGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And another summary."
      ]
    },
    {
      "metadata": {
        "id": "2RFml7PPzJjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of unique values in each column\n",
        "# What about viewing the number of unique values? \n",
        "\n",
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScrqVAQ6csAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And another summary."
      ]
    },
    {
      "metadata": {
        "id": "n-Zb_yR3zMUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check data types\n",
        "\n",
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbduA87McuV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And yet another summary."
      ]
    },
    {
      "metadata": {
        "id": "yy0CqoR0dBir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We should also do some checks of our data, to make sure everything is ok.\n",
        "\n",
        "Some ideas:\n",
        "\n",
        "1. order_hour_of_day should be between 1 to 24\n",
        "2. order_dow should be between 1 to 7\n",
        "3. pet should be 0 or 1\n",
        "4. Reordered should be 0 or 1\n",
        "\n",
        "We could do this in a hack-y way by just looking at the \"value counts\" for each variable, or we could write a function that checks each of these conditions. I'll do it the hacky way since it's fast and easy to visualize."
      ]
    },
    {
      "metadata": {
        "id": "DzYQm0DWM2X1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Insert code here for order_hour_of_day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yr16bFDvcxxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Insert code here for order_dow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byUI4ZX7fzdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Insert code here for pet value counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvZN_YIHf2se",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Insert code here for reordered value counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9k8muqRhWV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary cell."
      ]
    },
    {
      "metadata": {
        "id": "u-VIa-VtHZtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The data is cleaned, so now we can explore.\n",
        "\n",
        "Keep in mind that while we explore we may see some anomalies pop up. Seeing anomalies imply that there's still some cleaning that needs to be done, and it's normal to go back and forth between exploration and updating the cleaning process.\n",
        "\n",
        "Since our end goal is to build a model to predict if someone is a pet owner or not, we want to explore the difference between pet owners (pet column = 1) and non-pet owners (pet column = 0).\n",
        "\n",
        "As is typical for data scientists, the exploratory data analysis (EDA) part of the workflow involves a lot of plotting and visualization. As such, let's load in the two plotting libraries we mentioned.\n",
        "\n",
        "Note that in this part of the talk, I'll go a bit faster and focus on the process of exploring the data, rather than the code and how to create the figures themselves. Please feel free to study the code on your own time, and ask questions if they come up. Plotting is something that takes a while to perfect (I'm not great at it!) so if you have any suggestions on how to improve these, please let me know! "
      ]
    },
    {
      "metadata": {
        "id": "RGaaw8cbzc-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isJhgP8jooN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Number of purchases per day of week, for both pet owners and non-pet owners."
      ]
    },
    {
      "metadata": {
        "id": "Qiv86CuO0X3X",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  # First we use matplotlib (plt) to plot out 2 figures.\n",
        "  # The first figure will be for pet owners,\n",
        "  # the second will be for non-pet owners.\n",
        "  # Then we use seaborn to make our plots.\n",
        "  f, axes = plt.subplots(1, 2, figsize=(20,7), sharex=True)\n",
        "  plt.figure(figsize=(20,8))\n",
        "  g1 = sns.countplot(x=\"order_dow\", data=df[df.pet==1], ax=axes[0])\n",
        "  g1.set_title(\"pet owner\")\n",
        "  g2 = sns.countplot(x=\"order_dow\", data=df[df.pet==0], ax=axes[1])\n",
        "  g2.set_title(\"not pet owner\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpBylkHKpJdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "bR47w7h91C4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I can already see that I'm going to repeat this sort of figure a few times..\n",
        "# so it's useful to wrap this in a function.\n",
        "\n",
        "def count_plot(col):\n",
        "  \n",
        "  f, axes = plt.subplots(1, 2, figsize=(20,7), sharex=True)\n",
        "  plt.figure(figsize=(20,8))\n",
        "  g1 = sns.countplot(x=col, data=df[df.pet==1], ax=axes[0])\n",
        "  g1.set_title(\"pet owner\")\n",
        "  g2 = sns.countplot(x=col, data=df[df.pet==0], ax=axes[1])\n",
        "  g2.set_title(\"not pet owner\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ts0frqUoo9Pp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Count plot of  order hour of day for pet owners and non-pet owners."
      ]
    },
    {
      "metadata": {
        "id": "SmB940RD0ora",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_plot(\"order_hour_of_day\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwhZEmiYpK34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "v7vCcb4QpCdA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Count plot for number of purchases in each department from for pet owners and non-pet owners."
      ]
    },
    {
      "metadata": {
        "id": "RknzJMzH1KXw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_plot(\"department_id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksLMATjTpMNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "B4QISvEXpN3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Histogram of department purchases, for pet owners and non-pet owners.\n",
        "\n",
        "This is a similar way to view the same thing as above, except we're looking at relative frequencies rather than absolute counts."
      ]
    },
    {
      "metadata": {
        "id": "RDl7kiPr1Ooz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def proportion_plot_both_groups(data):\n",
        "        \n",
        "    x, y, hue = \"department\", \"purchase_proportion\", \"pet\"\n",
        "    hue_order = [\"pet owner\", \"non pet owner\"]\n",
        "    plt.figure(figsize=(10,6))\n",
        "    (data[x]\n",
        "     .groupby(data[hue])\n",
        "     .value_counts(normalize=True)\n",
        "     .rename(y)\n",
        "     .reset_index()\n",
        "     .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue))\n",
        "    plt.xticks(rotation='45')\n",
        "    l = plt.legend(loc=\"upper right\")\n",
        "    l.set_title('Non-pet owners (0) vs pet owners (1)')\n",
        "\n",
        "proportion_plot_both_groups(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHd13Ey4plKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "Zk0NPm6jpv9j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Department reordering tendencies of pet owners and non-pet owners.\n",
        "\n",
        "### Department reorder ratio is the ratio of how many times a pet owner/non-pet owner reorders from a certain department, versus how often they do not reorder (reorder a new item). For example, a 0.55 department reorder ratio for pet owners for department A would mean that 55% of pet owners' orders from department A are items they are reordering."
      ]
    },
    {
      "metadata": {
        "id": "Lvuwkstf2l-D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reorders_plot_both_groups(data):\n",
        "            \n",
        "    plot_title=\"Department wise reorder ratio: Pet owners vs non pet owners\"\n",
        "    grouped_df = data.groupby([\"department\",\"pet\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.pointplot(grouped_df['department'].values, grouped_df['reordered'].values, \n",
        "                  alpha=0.8, hue=grouped_df[\"pet\"])\n",
        "    plt.ylabel('Reorder ratio', fontsize=12)\n",
        "    plt.xlabel('Department', fontsize=12)\n",
        "    plt.title(plot_title, fontsize=15)\n",
        "    plt.xticks(rotation='45')\n",
        "    plt.show()\n",
        "\n",
        "reorders_plot_both_groups(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eH3klHz1qYr3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "dW-JPaIsqIiO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Day of week reordering tendencies for pet owners and non-pet owners.\n",
        "\n",
        "### Day of week reorder ratio is how often a group reorders items on a particular day of week, versus how much they do not reorder (order a new item). For example, a reorder ratio of 0.7 means that 70% of purchases are items that are being reordered."
      ]
    },
    {
      "metadata": {
        "id": "m44QqAaM36nC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reorders_dow_both_groups(group):\n",
        "    plot_title = \"Reorder ratio across day of week for {group} and non-{group}\".format(group=group)\n",
        "    grouped_df = df.groupby([\"order_dow\", group])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(grouped_df['order_dow'].values, grouped_df['reordered'].values, \n",
        "                alpha=0.8, hue=grouped_df[group])\n",
        "    plt.ylabel('Reorder ratio', fontsize=12)\n",
        "    plt.xlabel('Day of week', fontsize=12)\n",
        "    plt.title(plot_title, fontsize=15)\n",
        "    plt.xticks(rotation='horizontal')\n",
        "    plt.ylim(0.5, 0.7)\n",
        "    plt.show()\n",
        "\n",
        "reorders_dow_both_groups(\"pet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsnEI1rcqbc8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "sx-IfrypEP1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now let's look at things more at the user-level.\n",
        "\n",
        "## First we'll look at the number of unique department purchases a shopper makes. We'll plot the results aggregated to the pet-owner vs non-pet owner level.\n"
      ]
    },
    {
      "metadata": {
        "id": "UQVJwz7rETyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of unique department purchases\n",
        "\n",
        "def plot_group_proportions(feature_df, order_data, col, group, n, format_xticks, title):\n",
        "    data = feature_df.merge(order_data[[\"user_id\", group]].drop_duplicates(), on = \"user_id\")\n",
        "    x, y, hue = col, \"Relative Frequency\", group\n",
        "    hue_order = [group, \"not_{}\".format(group)]\n",
        "    plt.figure(figsize=(12,6))\n",
        "    (data[x]\n",
        "     .groupby(data[hue])\n",
        "     .value_counts(normalize=True)\n",
        "     .rename(y)\n",
        "     .reset_index()\n",
        "     .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue))\n",
        "    plt.xticks(rotation='45')\n",
        "    ax = plt.gca()\n",
        "    if format_xticks is True:\n",
        "        for index, label in enumerate(ax.xaxis.get_ticklabels()):\n",
        "            if index % n != 0:\n",
        "                label.set_visible(False)\n",
        "    l = plt.legend(loc=\"upper right\")\n",
        "    l.set_title('Non-{group} (0) vs {group} (1)'.format(group=group))\n",
        "    plt.title(title)\n",
        "\n",
        "def get_num_unique_dept_purchases(data):\n",
        "    num_unique_dept = data.groupby([\"user_id\"])[\"department\"].aggregate(\"nunique\").reset_index()\n",
        "    num_unique_dept.columns = [\"user_id\", \"num_departments_purchased_from\"]\n",
        "    return num_unique_dept\n",
        "\n",
        "num_unique_dept = get_num_unique_dept_purchases(df) # Feature\n",
        "title = \"Number of unique departments purchased from: Non-{g}/{g} groups\"\n",
        "col_name = \"num_departments_purchased_from\"\n",
        "plot_group_proportions(num_unique_dept, df, col_name, \"pet\", 0, False, title.format(g=\"pet\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jphnqFxrLX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "HFffBQv-rOT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Average time of day of shopper visit."
      ]
    },
    {
      "metadata": {
        "id": "uGtWkUTUFDU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Average time of day of shopper visit\n",
        "\n",
        "def get_avg_tod(data):\n",
        "    avg_tod = data.groupby([\"user_id\"])[\"order_hour_of_day\"].aggregate(\"mean\").reset_index(name=\"avg_tod\")\n",
        "    avg_tod[\"avg_tod\"] = round(avg_tod[\"avg_tod\"])\n",
        "    return avg_tod\n",
        "\n",
        "avg_tod = get_avg_tod(df)\n",
        "title = \"Average time of day of shopper visit: Non-{g}/{g} groups\"\n",
        "col_name = \"avg_tod\"\n",
        "plot_group_proportions(avg_tod, df, col_name, \"pet\", 1, True, title.format(g=\"pet\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6k1Qu9GjFcbq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "kJiCZMI5rSTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Average day of the week that shoppers visit the store."
      ]
    },
    {
      "metadata": {
        "id": "wiwR9Z7_FcvR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Average day of week of visit\n",
        "def get_avg_dow(data):\n",
        "    avg_dow = data.groupby([\"user_id\"])[\"order_dow\"].aggregate(\"mean\").reset_index(name=\"avg_dow\")\n",
        "    avg_dow[\"avg_dow\"] = round(avg_dow[\"avg_dow\"])\n",
        "    return avg_dow\n",
        "\n",
        "avg_dow = get_avg_dow(df)\n",
        "title = \"Average day of week of shopper visit: Non-{g}/{g} groups\"\n",
        "col_name = \"avg_dow\"\n",
        "plot_group_proportions(avg_dow, df, col_name, \"pet\", 1, True, title.format(g=\"pet\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O935rlAUrrhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "LIxuMKpdrtSY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## User's individual reorder rate. The percentage of orders of an item they make that are reorders.\n",
        "\n",
        "Admittedly, this plot looks a bit strange. There are huge spikes at 0, 0.1, 0.2... etc... probably a rounding error on my part but let's just ignore it for now :upside_down_face: :) "
      ]
    },
    {
      "metadata": {
        "id": "WvKpI2VKF2Q7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# User's individual reorder rate, i.e. percentage of orders that are reorders\n",
        "def get_user_reorder_rate(data):\n",
        "    user_reorder_rate = data.groupby([\"user_id\"])[\"reordered\"].aggregate(\"mean\").reset_index(name=\"user_reorder_rate\")\n",
        "    user_reorder_rate[\"user_reorder_rate\"] = round(user_reorder_rate[\"user_reorder_rate\"],2)\n",
        "    return user_reorder_rate\n",
        "\n",
        "user_reorder_rate = get_user_reorder_rate(df)\n",
        "title = \"Proportion of reorders across all departments: Non-{g}/{g} groups\"\n",
        "col_name = \"user_reorder_rate\"\n",
        "plot_group_proportions(user_reorder_rate, df, col_name, \"pet\", 12, True, title.format(g=\"pet\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKMBYy21uOxP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary text."
      ]
    },
    {
      "metadata": {
        "id": "5KvpZ6myuQ7q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# And that's it! Exploratory data analysis, done! Step 1, done!\n",
        "\n",
        "# Now onto the real fun part: modelling!\n",
        "\n",
        "Stay tuned for part 2 :) "
      ]
    }
  ]
}
